\section{Anforderungen an den GPU Algorithmus}

Aufgrund der unterschiedlichen Architektur von CPUs und GPUs kann der RSH-Extraktor nicht einfach portiert werden, sondern muss, mit Fokus auf die Vor- und Nachteile einer GPU, neu entwickelt werden. Eine CPU hat -- verglichen mit einer GPU -- sehr wenige parallele Ausf"uhrungseinheiten, daf"ur einen gr"o"seren Befehlssatz und deutlich mehr Steuerlogik, wodurch CPUs ihre Ausf"uhrungsressourcen besser auslasten k"onnen. Somit sind CPUs besser geeignet f"ur Berechnungen mit geringer Datenparallelit"at. GPUs sind aufgrund ihrer geringen Steuerlogik und ihrer hohen Anzahl an parallelen Ausf"uhrungseinheiten f"ur Berechnungen geeignet, die eine hohe Datenparallelit"at aufweisen. Die Effizienz des Extraktionsprozesses h"angt deswegen sehr stark von der F"ahigkeit ab, die n"otigen Berechnungen so gut wie m"oglich zu parallelisieren. 

Die unterschiedlichen Cache-Hierarchien und -Typen stellen ebenfalls eine Herausforderung dar. Um das volle Potential einer GPU auszunutzen, reicht es nicht einfach nur massiv zu parallelisieren, sondern es muss beachtet werden, auf welche Speicherbereiche zugegriffen werden kann. Eine GPU bietet allgemein drei Speicherbereiche mit mit unterschiedlichen Eigenschaften:
% joggel hats gesagt
\begin{itemize}
	\item Privater Speicher: Nur ein Thread hat Zugriff (sehr schnell)
	\item Lokaler Speicher: Threads einer Arbeitsgruppe haben Zugriff (schnell)
	\item Globaler Speicher: Alle Threads haben Zugriff (langsam)
\end{itemize}
Dar"uber hinaus ist es nicht m"oglich, Threads global zu synchronisieren. F"ur Berechnungen, die keinerlei Abh"angigkeiten haben, ist dies unproblematisch. Bei der Multiplikation zweier gro"ser Zahlen kann zum Beispiel die Multiplikation der einzelnen Bl"ocke komplett parallel nach der Schulbuchmethode durchgef"uhrt werden. Die anschlie"senden Additionen k"onnen jedoch nicht ohne weiteres parallelisiert werden, da Datenabh"angigkeiten bestehen. Es ist m"oglich, die Additionen in $\log(N)$ Schritten durchzuf"uhren, indem jede Ebene des Additionsbaumes komplett parallelisiert wird (siehe \cite{haque2012plain} Kapitel 3 f"ur eine detaillierte Erkl"arung), allerdings m"ussen alle Operationen einer Ebene fertig sein, bevor zur n"achsten "ubergegangenen werden kann. Am Ende jeder Ebene muss daher synchronisiert werden. Threads auf der GPU k"onnen nur lokal synchronisiert werden, was bedeutet, dass bei diesem Beispiel nicht das komplette Potential der GPU ausgereizt werden kann, sondern maximal das Potential einer Arbeitsgruppe, wodurch Einschr"ankungen entstehen.

Um den Implementierungsaufwand zu minimieren, wurde nach bereits existierenden Algorithmen in Form von Bibliotheken oder "ahnlichem gesucht, welche die ben"otigten mathematischen Berechnungen bereits implementieren. Ein "Uberblick "uber die gefundenen Bibliotheken wird im n"achsten Kapitel gegeben.