\section{Anforderungen an den GPU Algorithmus}

Aufgrund der unterschiedlichen Architektur von CPUs und GPUs, kann der RSH-Extraktor nicht einfach portiert werden, sondern muss, mit Fokus auf die Vor- und Nachteile einer GPU, neu entwickelt werden. Eine CPU hat - verglichen mit einer GPU - sehr wenige parallele Ausf"uhrungseinheiten, daf"ur einen gr"o"seren Befehlssatz und deutlich mehr Steuerlogik, wodurch CPUs ihre Ausf"uhrungsressourcen deutlich besser auslasten k"onnen. Somit sind CPUs besser geeignet f"ur Berechnungen die eine geringe Datenparallelit"at haben. GPUs sind aufgrund ihrer geringen Steuerlogik und ihrer hohen Anzahl an parallelen Ausf"uhrungseinheiten f"ur Berechnungen geeignet die eine hohe Datenparallelit"at haben. Die Effizienz des Extraktionsprozesses h"angt deswegen sehr stark von der F"ahigkeit ab, die n"otigen Berechnungen so gut wie m"oglich zu parallelisieren. 

Die unterschiedlichen Cache-Hierarchien und -Typen stellen ebenfalls eine Herausforderung dar. Um das volle Potential einer GPU auszunutzen reicht es nicht einfach nur massiv zu parallelisieren, sondern es muss beachtet werden, auf welche Speicherbereiche zugegriffen werden kann. Eine GPU bietet im Allgemeinen drei Speicherbereiche:
\begin{itemize}
	\item privater Speicher: Nur ein Thread hat zugriff (sehr schnell)
	\item lokaler Speicher: Threads einer Arbeitsgruppe haben zugriff (schnell)
	\item globaler Speicher: Alle Threads haben zugriff (langsam)
\end{itemize}
Dar"uber hinaus ist es nicht m"oglich Threads global zu synchronisieren. F"ur Berechnungen die keinerlei Abh"angigkeiten haben, ist das kein Problem. Bei der Multiplikation zweier gro"ser Zahlen kann z.B. die Multiplikation der einzelnen Bl"ocke komplett parallel nach der Schulmethode durchgef"uhrt werden. Die anschlie"senden Additionen k"onnen jedoch nicht ohne weiteres parallelisiert werden, da Datenabh"angigkeiten bestehen. Es ist m"oglich die Additionen in $\log(N)$ Schritten durchzuf"uhren, indem jede Ebene des Additionsbaumes komplett parallelisiert wird (Siehe \cite{haque2012plain} Kapitel 3 f"ur eine detaillierte Erkl"arung), allerdings m"ussen alle Operationen einer Ebene fertig sein, bevor zur n"achsten Ã¼bergegangenen werden kann, d.h. am Ende jeder Ebene muss synchronisiert werden. Threads auf der GPU k"onnen nur lokal synchronisiert werden, das bedeutet, dass bei diesem Beispiel nicht das komplette Potential der GPU ausgereizt werden kann, sondern maximal das Potential einer Arbeitsgruppe, wodurch Einschr"ankungen entstehen k"onnen.

Um den Implementierungsaufwand zu minimieren, wurde nach bereits existierenden Algorithmen in Form von Bibliotheken oder "ahnlichem gesucht, welche die ben"otigten mathematischen Berechnungen bereits implementieren. Ein "Uberblick "uber die gefundenen Bibliotheken wird im n"achsten Kapitel gegeben.